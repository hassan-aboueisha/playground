Puzzles
-------

The mean heights of men and women in a population were calculated to be image00 and image01. What is the mean height of the total population?




A recent poll revealed that a third of the cars in Italy are Ferraris, and that half of those cars are red. If you spot a red car approaching from a distance, what is the likelihood that it is a Ferrari?




Imagine a test with a true positive rate of 100% and false positive rate of 5%. Imagine a population with a 1/1000 rate of having the condition the test identifies. Given a positive test, what is the probability of having that condition?




You’re trying to find the best place to put in an advertisement banner on your website. You can make the size (thickness) small, medium or large, and choose vertical position top, middle or bottom. At least how many total page visits (n) and ad clicks (m) do you need to say with 95% confidence that one of the designs performs better than all the other possibilities?




A dairy farmer is trying to understand the factors that affect milk production of her cattle. She has been keeping logs of the daily temperature (usually 30-40°C), humidity (60-90%), feed consumption (2000-2500 kgs), and milk produced (500-1000 liters). How would approach the goal of predicting liters of milk produced in a day?




The x and y are two random variables and their standard errors are known. How can you calculate/estimate the standard error in f(x,y)? If you want, specifically, in f(x,y) = y/x. How would you do this if you had all the data (x_i, y_i)?




Certain third party data providers (DP1, DP2 ...) will identify cookie_ids as belonging to a specific demographic segment, say DP1_S1 = F35-44. To test the accuracy of this assignment, random samples of cookie_ids in these segments are measured against an industry standard source of "ground truth". This will yield data like "40% of the cookie_ids that DP1 identifies as in S1 are actually (according to "ground truth") in F35-44" and "30% of the cookie_ids that DP2 identifies as in S5 are actually (according to "ground truth") in F35-44". Given the above, what is the probability that a cookie_id that is in both DP1_S1 and DP2_S5 will be found to be in F35-44 according to the industry standard source of ground truth?




Climate data collected over the past century reveals a cyclic pattern of rising and falling temperatures. How would you model this data (a sequence of average annual temperature values) to predict the average temperature over the next 5 years?




Your job at an online news service is to collect text reports from around the world, and present each story as a single article with content aggregated from different sources. How would you go about designing such a system? What ML techniques would you apply?




You’re about to get on a plane to Seattle. You want to know if you should bring an umbrella. You call 3 random friends of yours who live there and ask each independently if it’s raining. Each of your friends has a 2/3 chance of telling you the truth and a 1/3 chance of messing with you by lying. All 3 friends tell you that “Yes” it is raining. What is the probability that it’s actually raining in Seattle?




You are compiling a report for user content uploaded every month and notice a spike in uploads in October. In particular, a spike in picture uploads. What might you think is the cause of this, and how would you test it?



You have data on the durations of calls to a call center. Generate a plan for how you would code and analyze these data. Explain a plausible scenario for what the distribution of these durations might look like. How could you test, even graphically, whether your expectations are borne out?



There’s one box - has 12 black and 12 red cards, 2nd box has 24 black and 24 red; if you want to draw 2 cards at random from one of the 2 boxes, which box has the higher probability of getting the same color? Can you tell intuitively why the 2nd box has a higher probability



You are about to send one million email (marketing campaign). How do you optimize delivery and its response? Can both of these be done separately?



How would you perform clustering in one million unique keywords, assuming you have 10 million data points and each one consists of two keywords and a metric measuring how similar these two keywords are? 



Do you know about the Netflix Prize problem? How would you approach it?



How to do customer recommendation?



How would you generate related searches for a search engine?



How would you suggest followers on Twitter?


