
Feature selection
-------

How do you select features? What are some good ways for performing feature selection that do not involve exhaustive search?:

  - EDA
  
  - Mutual information
  Measurethe reduction of uncertainty in Y after observing X. It is the KL distance between the joint density and the product of the individual densities. it measures how much knowing one of these variables reduces uncertainty about the other
  Cons: biased towards high cardinality features

  - Correlation
  * Spearman: monolitically rank
  * Pearson: linear relationship

  - Statistical tests
  f-test
  chi squared

  - Stepwise selection
  
  - Lasso

  - AIC
  . -2*ln(likelihood) + 2*k,
  AIC tries to select the model that most adequately describes an unknown, high dimensional reality
  the results point to the fact that AIC is too liberal and still frequently prefers a more complex, wrong model over a simpler, true model

  - BIC
  . -2*ln(likelihood) + ln(N)*k
  BIC tries to find the TRUE model among the set of candidates


What to do with categorical variables of high cardinality?:

  1. Clustering on the behaviour you want to capture 
  2. Learning representations (auto-encoder, pca, matrix factorization, word2vec)
  3. Replace by informative number (conversion, demand, ...)
  4. Hashing trick
  5. Group rare ones
  6. Replace by frequency on the training set (non-linear methods)

  ? pros and cons

Can a feature that doesnt help alone, be useful when another feature is added?:



Regularization
-------

What is Regularization and what does it try to solve?:

  Regularization is a way of penalizing big coefficients on linear models, to prevent overfitting.
  Most of the models follow this equation: B -> min(loss(X,Y|B) + penalty(B))

  - Ridge:
  y||B||^2
  A type of shrinkage regularization (it shrinks the coefficients instead of zeroing them)
  Differentiable (friendly to gradient-based methods)
  Assumption: Gaussian prior of coefficients
  Stable 

  - Lasso
  y||B||
  Promotes feature selection (correlated coefficients will zero)
  Assumption: Laplace prior of coefficients
  Unstable ( 0_4 has the same loss as 2_2 )

  - Elastic Net
  Weighted lasso and ridge
  y1||B||  + y2||B||^2

  - Dropout
  Randomly deactivates neuros on a neural network
  * preventing multiple neurons learning the same thing
  * forcing the neural networl to learn the signal
  ?


What is the difference in the outcome (coefficients) between the L1 and L2 norms? (usually I ask them to draw the geometric shape of the functions, just to make sure):

  L1: select
  L2: shrink

  Plot alpha x coefficients

Why (geometrically) does LASSO produce solutions with zero-valued coefficients (as opposed to ridge)?:

  ? diamond shape


Let us go through the derivation of OLS or Logistic Regression. What happens when we add L2L2 regularization? How do the derivations change? What if we replace L2L2 regularization with L1L1 regularization?:




Evaluation
-------

How do you evaluate a model?:



What’s the trade-off between bias and variance?:

  E[e] = bias^2 + variance + noise

How do you estimate performance on unseen data?:



You have built several different models. How would you select the best one?:



What is sensitivity analysis? Is it better to have low sensitivity and low predictive power?:



How do you perform good cross-validation? What are the options?:



How would you convinvce someone else that this method is not overfitting?:



What is the difference between holding out a validation set and doing 10-Fold CV?:



What do you think about the idea of injecting noise in your data set to test the sensitivity of your models?:



Which is better: Too many false positives or too many false negatives?:



How do you ensure you’re not overfitting with a model?:



Explain what resampling methods are and why they are useful. Also explain their limitations:




Fitting
-------

What is the Gradient Descent Method (the intuition is mostly enough)?:

  - Batch
  Update B to the rate of its steepest direction. 
  for i in epochs
    B = B - a * gradient_B( loss(X,y,B)) 

  - Stochastic
  Estimate B applying the gradient successfully for each instance.
  for i in epochs
    data = shuffle(data)
    for x,y in data
      B = B - a * gradient_B( loss(x,y,B)) 

Does the Gradient Descent method always converge to the same point?:

  Batched: yes
  Stochastic: on one epoch yes, normally we shuffle before second, which would mean a different convergence path.

Is it necessary that the Gradient Descent Method will always find the global minima?:

  No, depends on learning rate and convexity of loss function.

  Learning rate: it can oscilate around minima or diverge on big learning rates
  Non-convex: can be stuck on local minima or saddle points

Common optimizations Gradient Descent?:

  - In general:
  Adaptive learning rate
  Batch x min-batch x stochastic
  Batch normalization (renormalizes coefficients during training)
  Early stopping

  - Blah
  Momentum (add fraction of last update to the current)
  Adagrad (adapts learning rate to parameters )
  Adadelta( modification to adagrad to prevent monotically decreasing learning rate)
  Adam ( adapts learning rate and momentum to parameters )

  - For non convexity
  "As has been shown, SGD usually achieves to find a minimum, but it might take significantly longer than with some of the optimizers, is much more reliant on a robust initialization and annealing schedule, and may get stuck in saddle points rather than local minima"

What are alternatives to gradient descent? Pros and cons?:

  Newton method
  BFGS
  L-BFGS
  IRLSM

How maximum likelihood works?:

  L( theta | data ) = P( data | theta )
  We can find theta that maximizes the likelihodd (probability of seeing this data, under the theta distribution)

  - Assuming observations are independent
  L(theta) = product[x]( L(theta) )
  or
  L(theta) = sum[x]( ll(x, theta) )

  - Algorithm
  while B converges
    sum_ll = sum[x]( ll(theta) )
    B < max(sum_ll)

Whats the difference between convex vs nonconvex?:

  - Convex
  we can draw an ininterrupted line between any point in a curve.
  gradient(curve) = 0 leads to only one solution (only one local minima-maxima)

  - Non convext
  Numerical optimization that uses gradient arent guaranteed to find global minima

  ? how to detect convexity


Is it always bad to have local optima?:

  - Nope.
  Local optima more often than not is correlated with global optima
  Time x benefit


Whats EM?:




How do you tune hyperparameters? Any method beyond grid search?:



How Monte Carlo can be used for fitting?:




Data exploration
-------

How do you summarize the distribution of your data?:



How do you handle outliers or data points that skew data?:



What assumptions can you make? Why and when? (i.e When is it safe to assume "normal"):


How to efficiently represent 5 dimension in a chart or in a video?:



How would you handle an imbalanced dataset?:



How do you handle missing or corrupted data in a dataset?:

