Dimensionality
------

1. What is the curse of dimensionality?:

  

2. What is the difference between density-sparse data and dimensionally-sparse data?:



3. What does "higher dimensionality" imply when applying textbook clustering algorithms developed for low dimension metric spaces to, say, numerical text analysis? Think of using cluster density to identify "good" clusters.



What is the purpose of dimensionality reduction and why do we need it?



Are dimensionality reduction techniques supervised or not? Are all of them are (un)supervised?



What ways of reducing dimensionality do you know?



Is feature selection a dimensionality reduction technique?



What is the difference between feature selection and feature extraction?



Is it beneficial to perform dimensionality reduction before fitting an SVM? Why or why not?


=========================== PCA

Overview
------

Explain how it works in a few words:



Whats the metric the model tries to optimize?:



Algorithm / Fitting
-------

Which method do you use to fit your model?:



What's the complexity?:



Pseudo-code (with formulas):



How do you need to prepare the data for the model? (categorical? missing? outliers? scale? variance?):



Does the model have convergence problems? Does it have a random component or will the same training data always generate the same model? How do we deal with random effects in training?:



Explain how {core feature} is done:



How many parameters the model has to learn? is is feasible setup?:



Evaluation
-------

How you evaluate quality/performance of your model? Why not metric ______?:



How interpretable is the model?:



Does the model have any meta-parameters and thus require tuning? What are they? How would you choose the best one?:



Are the predictions calibrated? If not how should they be calibrated?:



Is it prone to over-fitting? How do you detect? What can be done about this?:




Model selection
-------

Does the model make any important assumptions about the data? When might these be unrealistic? How do we examine the data to test whether these assumptions are satisfied?:

  - Why do we need to center data for PCA and what can happen if we donâ€™t do it?
  - Do we need to normalize data for PCA? Why?


What alternative models might we use for the same type of problem that this one attempts to solve, and how does it compare to those?:

  - How is it related to eigenvalue decomposition (EVD)?
  - How will you use SVD to perform PCA? When SVD is better than EVD for PCA?
  - What are the differences between Factor Analysis and Principal Component Analysis?


Can it learn non-linearities? If so, how so? If not, is there any way around it?:

  - Is it learn?



