Missing:

- practical problems (problem definition, sampling negatives, biases in the data, ...)
- model selection
- deployment
- 


Experience
-------

What is the biggest data set that you have processed and how did you process it? What was the result?

Tell me two success stories about your analytic or computer science projects? How was the lift (or success) measured?

What's are the most important points for a ML to thrive?


Data: exploration
-------

How do you summarize the distribution of your data?:

How do you find/handle outliers or data points that skew data?:

What assumptions can you make? Why and when? (i.e When is it safe to assume "normal"):

How to efficiently represent 5 dimension in a chart or in a video?:

How would you handle an imbalanced dataset?:

How do you handle missing or corrupted data in a dataset?:


Data: Dimensionality
------

What is the curse of dimensionality?:

What is the difference between density-sparse data and dimensionally-sparse data?:

What is the purpose of dimensionality reduction and why do we need it?:

What ways of reducing dimensionality do you know? Pros and cons?:


Data: Transformation
-------

Explaing power transforms:

What is Box-Cox transformation? :

When to do transformations?:

How would you turn unstructured data into structured data?:

How to check if a distribution is close to Normal? Why would you want to check it? What is a QQ Plot?:


Data: selection
-------

How do you select features? What are some good ways for performing feature selection that do not involve exhaustive search?:

What to do with categorical variables of high cardinality?:

Can a feature that doesnt help alone, be useful when another feature is added?:


Optimization
-------

What is the difference between supervised learning and unsupervised learning? Give concrete examples:

What is the Gradient Descent Method (the intuition is mostly enough)?:

Does the Gradient Descent method always converge to the same point?:

Is it necessary that the Gradient Descent Method will always find the global minima?:

Common optimizations Gradient Descent?:

What are alternatives to gradient descent? Pros and cons?:

How maximum likelihood works?:

Whats the difference between convex vs nonconvex?:

Is it always bad to have local optima? How do you identify it?:

Whats EM?:

How do you tune hyperparameters? Any method beyond grid search?:

How Monte Carlo can be used for fitting?:


Regularization
-------

What is Regularization and what does it try to solve? What are the methods? How they compare?:

What is the difference in the outcome (coefficients) between the L1 and L2 norms? (usually I ask them to draw the geometric shape of the functions, just to make sure):

Let us go through the derivation of OLS or Logistic Regression. What happens when we add L2L2 regularization? How do the derivations change? What if we replace L2L2 regularization with L1L1 regularization?:


Evaluation
-------

How do you evaluate a model?:

How do you know if one algorithm is better than other?:

What is better: good data or good models? And how do you define “good”? Is there a universal good model? Are there any models that are definitely not so good?:

How to define/select metrics?:

What’s the trade-off between bias and variance?:

How do you estimate performance on unseen data?:

You have built several different models. How would you select the best one?:

What is sensitivity analysis? Is it better to have low sensitivity and low predictive power?:

How do you perform good cross-validation? What are the options?:

How would you convince someone else that this method is not overfitting?:

Explain what resampling methods are and why they are useful:

How to do it cross validation the right way?:


